import { useState, useCallback } from "react";
import { toast } from "sonner";
import { createSpeechRecognition } from "@/utils/speechUtils";
import { SpeechRecognitionState } from "@/types/speech";

export const useSpeechRecognition = (): SpeechRecognitionState => {
  const [isRecording, setIsRecording] = useState(false);
  const [capturedText, setCapturedText] = useState("");
  const [recognition, setRecognition] = useState<SpeechRecognition | null>(null);

  const startRecording = useCallback((onTextCaptured: (text: string) => void) => {
    console.log('üé§ Starting speech recognition...');
    const newRecognition = createSpeechRecognition();
    if (!newRecognition) {
      console.error('‚ùå Speech recognition not supported');
      return;
    }

    setRecognition(newRecognition);
    let silenceTimeout: NodeJS.Timeout;
    let hasSpoken = false;

    newRecognition.onstart = () => {
      console.log('üéôÔ∏è Speech recognition started');
      silenceTimeout = setTimeout(() => {
        console.log('‚è≤Ô∏è Checking silence timeout:', { hasSpoken, isRecording });
        if (!hasSpoken && isRecording) {
          console.log('üîá No speech detected, attempting to show toast...');
          toast("No Speech Detected", {
            description: "Please check your microphone and try speaking again.",
            action: {
              label: "Try Again",
              onClick: () => {
                console.log('üîÑ Try Again clicked');
                if (newRecognition) {
                  newRecognition.stop();
                  setIsRecording(false);
                  startRecording(onTextCaptured);
                }
              },
            },
          });
          console.log('üõë Stopping recognition due to silence');
          newRecognition.stop();
          setIsRecording(false);
        }
      }, 5000);
    };

    newRecognition.onresult = (event) => {
      console.log('üó£Ô∏è Speech detected!');
      hasSpoken = true;
      const transcript = Array.from(event.results)
        .map(result => result[0].transcript)
        .join(" ");
      console.log('üìù Transcript:', transcript);
      setCapturedText(transcript);
    };

    newRecognition.onend = () => {
      console.log('üèÅ Speech recognition ended', { hasSpoken, capturedText });
      clearTimeout(silenceTimeout);
      if (hasSpoken) {
        onTextCaptured(capturedText);
      }
      setIsRecording(false);
    };

    newRecognition.onerror = (event) => {
      console.error('üö® Speech recognition error:', event.error);
      if (event.error !== 'no-speech') {
        console.log('‚ö†Ô∏è Showing error toast');
        toast.error("Error", {
          description: "There was an error with speech recognition. Please try again.",
        });
      }
      clearTimeout(silenceTimeout);
      setIsRecording(false);
    };

    try {
      console.log('‚ñ∂Ô∏è Attempting to start recognition');
      newRecognition.start();
      setIsRecording(true);
    } catch (error) {
      console.error('üí• Error starting speech recognition:', error);
      toast.error("Error", {
        description: "Failed to start speech recognition. Please try again.",
      });
      setIsRecording(false);
    }
  }, [capturedText, isRecording]);

  const stopRecording = useCallback(() => {
    console.log('‚èπÔ∏è Manual stop recording requested');
    if (recognition) {
      recognition.stop();
    }
  }, [recognition]);

  return {
    isRecording,
    capturedText,
    setCapturedText,
    startRecording,
    stopRecording,
  };
};